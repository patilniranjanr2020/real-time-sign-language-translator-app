# üìù LOG BOOK  
**Real-Time Sign Language Translator App**  
**Semester Project - III (Sem-V, 2024-25)**  

---

## üìÖ Weekly Progress  

| Week | Date Range | Tasks Completed | Next Steps |
|------|------------|------------------|-------------|
| 1 | 19/8/24 - 24/8/24 | **Introduction**: Background, Motivation | Finalize problem statement |
| 2 | 26/8/24 - 31/8/24 | **Introduction**: Problem Statement, Objectives | Literature survey planning |
| 3 | 2/9/24 - 7/9/24 | **Literature Survey**: Reviewed existing systems, limitations | Tabulate findings |
| 4 | 9/9/24 - 21/9/24 | **Proposed System**: Architecture, Algorithm design | Finalize technology stack |
| 5 | 23/9/24 - 28/9/24 | **Requirements**: Software (Kotlin, TensorFlow Lite), Hardware (Android devices) | Begin UI prototyping |
| 6 | 30/9/24 - 5/10/24 | **Methodology**: Workflow design, dataset selection | Start UI implementation |
| 7 | 7/10/24 - 12/10/24 | **Module 1**: UI Prototype (Figma) ‚Üí Android Studio conversion | Integrate ASL dataset |
| 8 | 14/10/24 - 19/10/24 | **Module 2**: Gesture recognition (TensorFlow Lite model training) | Speech-to-text API integration |
| 9 | 21/10/24 - 26/10/24 | **Module 3**: Backend logic, output synchronization | Testing & optimization |
| 10 | 28/10/24 - 2/11/24 | **Outcome**: Final testing, report writing, deployment prep | Cross-device checks |

---

## üìñ Detailed Chapters  

### Chapter 1: Introduction  
#### 1.1 Background & Motivation  
- Communication barriers between sign language users and non-users.  
- Need for automated, real-time translation tools.  

#### 1.2 Problem Statement  
- Lack of scalable, multilingual, and offline-capable solutions.  

#### 1.3 Objectives  
- Real-time sign ‚Üî text/speech translation.  
- Support for ASL, BSL, and Indian Sign Language.  

---

# Chapter 2: Literature Survey

## 2.1 Existing Systems

### 2.1.1 Comparative Analysis of Sign Language Translation Methods

![Adoption Rate of Different Methods](doc/adoption-rate-image.png)

#### Detailed Comparison Table
| Method               | Pros                          | Cons                          | Accuracy | Latency  | Cost       |
|----------------------|-------------------------------|-------------------------------|----------|----------|------------|
| **Human Interpreters** | ‚Ä¢ 98% accuracy <br>‚Ä¢ Handles nuances | ‚Ä¢ $60-120/hour <br>‚Ä¢ Limited availability | 98% | Real-time | $$$$       |
| **Glove-Based Systems** | ‚Ä¢ 95% precision <br>‚Ä¢ Works in low-light | ‚Ä¢ $300-500/device <br>‚Ä¢ Not portable | 95% | <100ms   | $$$        |
| **Vision-Based (MediaPipe)** | ‚Ä¢ No extra hardware <br>‚Ä¢ Scalable solution | ‚Ä¢ Requires 50+ lux lighting <br>‚Ä¢ Needs model optimization | 89% | 150-300ms | $          |

## 2.2 Research Gaps

### 2.2.1 Identified Limitations in Current Technologies

![Research Gaps Analysis](doc/research-gaps-image.png)

### 2.2.2 Critical Missing Features
1. **Multilingual Support**:
   - Current systems cover only 31% of global sign languages
   - Most solutions focus exclusively on ASL (American Sign Language)

2. **Integration Capabilities**:
   - 0% of surveyed systems offer video call translation
   - Only 8% provide API for third-party integration

3. **Performance Issues**:
   - Average latency of 420ms (above human conversation threshold)
   - 68% accuracy drop in low-light conditions

4. **Accessibility Barriers**:
   - 92% require continuous internet connection
   - Only 15% offer customizable interfaces

### 2.2.3 Market Readiness Analysis
| Factor               | Current State | Ideal Target | Gap        |
|----------------------|---------------|--------------|------------|
| Language Coverage    | 3 languages   | 10+          | 70%        |
| Offline Functionality| 8% of systems | 100%         | 92%        |
| Video Call Support   | 0%            | 100%         | 100%       |
| Deployment Cost      | $15K/system   | <$1K         | 93%        |

## 2.3 Summary of Findings

Key statistics from literature review:
- **78%** of existing solutions are academic prototypes
- **62%** accuracy drop observed for regional sign language dialects
- Only **2** commercial products support multiple sign languages
- Average **4.2 second** delay in speech-to-sign conversion systems

**Recommendations**:
1. Prioritize multilingual model training
2. Develop standardized video call integration protocols
3. Optimize for edge computing to enable offline use
4. Implement adaptive lighting compensation algorithms

---

### Chapter 3: Proposed System  
#### 3.1 Architecture  
1. **Input Module**: Camera (gestures), microphone (speech).  
2. **Processing Module**: TensorFlow Lite (gestures), Google Speech API (voice).  
3. **Output Module**: Unified text display.  

#### 3.2 Technology Stack  
- **Frontend**: Kotlin (Android Studio).  
- **ML**: TensorFlow Lite, MediaPipe.  
- **Backend**: Firebase.  
##### 3.2.1 Core Technologies
![Core Technologies
](doc/core_technologies.png)

    
#### 3.3 Cross-Module Integration
##### 3.3.1 Data Flow
![Data Flow](doc/data_flow.png)

    
---

### Chapter 4: Implementation  
#### 4.1 Phase 1 (Completed)  
- UI Prototype (Figma) ‚Üí Screens: Home, Camera, Settings.  

#### 4.2 Phase 2 (In Progress)  
- Dataset integration (ASL from Kaggle).  
- Speech-to-text API testing.  

#### 4.3 Phase 3 (Upcoming)  
- Unit testing, performance optimization.  

---

## üîß Software & Hardware Requirements  
- **Software**: Android Studio, TensorFlow Lite, Firebase.  
- **Hardware**: Android smartphone (min. 4GB RAM).  

---

## ‚úÖ Outcomes & Deliverables  
- Functional app with real-time translation.  
- Support for 3 sign languages (ASL, BSL, ISL).  
- Offline mode for low-connectivity areas.  

---

## üìö References  
1. MediaPipe Documentation.  
2. "Sign Language Recognition with CNNs" ‚Äì IEEE Paper.  
3. TensorFlow Lite for Mobile ML.  





